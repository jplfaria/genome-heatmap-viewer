{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: generate_ontology_tables() Function\n",
    "\n",
    "This notebook validates the `generate_ontology_tables()` function that creates\n",
    "ontology tables from a clade folder's db.sqlite file.\n",
    "\n",
    "**Author:** Jose P. Faria (jplfaria@gmail.com)  \n",
    "**Date:** February 2026\n",
    "\n",
    "## What this tests:\n",
    "1. Loading genome features from SQLite\n",
    "2. Extracting ontology terms (GO, EC, KEGG, COG, PFAM, SO, seed.role)\n",
    "3. Enriching terms from local parquet files\n",
    "4. Extracting relationships (GO is_a, seed.role → seed.reaction)\n",
    "5. Saving output tables (ontology_terms.tsv, ontology_definition.tsv, ontology_relationships.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]\n",
      "Pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the KBDatalakeApps lib to path\n",
    "sys.path.insert(0, '/home/jplfaria/repos/KBDatalakeApps/lib/KBDatalakeApps')\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Available Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Checking test data availability...\n",
      "============================================================\n",
      "  statements.parquet: OK (313.44 MB)\n",
      "  kegg_ko_definitions.parquet: OK (0.89 MB)\n",
      "  cog_definitions.parquet: OK (0.19 MB)\n",
      "  seed.json: OK (14.55 MB)\n",
      "  kegg_ko_ec_mapping.tsv: OK (0.21 MB)\n",
      "\n",
      "  Test database: OK\n"
     ]
    }
   ],
   "source": [
    "# Local parquet files location\n",
    "PARQUET_PATH = Path('/home/jplfaria/CDM_jose/ontology_data_utils/run_20250819_020438/parquet_files')\n",
    "\n",
    "# Test database (we'll copy this to a mock clade folder)\n",
    "TEST_DB = Path('/home/jplfaria/CDM_jose/ontology_data_utils/berdl_tables.db')\n",
    "\n",
    "# Check files exist\n",
    "print(\"=\" * 60)\n",
    "print(\"Checking test data availability...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "required_files = [\n",
    "    PARQUET_PATH / 'statements.parquet',\n",
    "    PARQUET_PATH / 'kegg_ko_definitions.parquet',\n",
    "    PARQUET_PATH / 'cog_definitions.parquet',\n",
    "    PARQUET_PATH / 'seed.json',  # Required for RAST → seed.role mapping\n",
    "    PARQUET_PATH / 'kegg_ko_ec_mapping.tsv',  # Required for KEGG KO → EC mapping\n",
    "]\n",
    "\n",
    "for f in required_files:\n",
    "    exists = f.exists()\n",
    "    size = f.stat().st_size / 1024 / 1024 if exists else 0\n",
    "    status = f\"OK ({size:.2f} MB)\" if exists else \"MISSING\"\n",
    "    print(f\"  {f.name}: {status}\")\n",
    "\n",
    "print(f\"\\n  Test database: {'OK' if TEST_DB.exists() else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in test database:\n",
      "  phenotype_module: 409 rows\n",
      "  genome: 42 rows\n",
      "  genome_ani: 7 rows\n",
      "  genome_features: 4,617 rows\n",
      "  pan_genome_features: 165,496 rows\n",
      "  ontology_definition: 8 rows\n",
      "  ontology_relationships: 7,483 rows\n",
      "  ontology_terms: 15,719 rows\n"
     ]
    }
   ],
   "source": [
    "# Check what tables are in the test database\n",
    "if TEST_DB.exists():\n",
    "    conn = sqlite3.connect(str(TEST_DB))\n",
    "    tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "    print(\"Tables in test database:\")\n",
    "    for t in tables['name']:\n",
    "        count = pd.read_sql(f\"SELECT COUNT(*) as cnt FROM {t}\", conn)['cnt'][0]\n",
    "        print(f\"  {t}: {count:,} rows\")\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Mock Clade Folder for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mock clade folder: /home/jplfaria/CDM_jose/ontology_data_utils/test_clade_s__Escherichia_coli\n",
      "Contents:\n",
      "  db.sqlite\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a mock clade folder structure\n",
    "MOCK_CLADE_FOLDER = Path('/home/jplfaria/CDM_jose/ontology_data_utils/test_clade_s__Escherichia_coli')\n",
    "\n",
    "# Clean up if exists\n",
    "if MOCK_CLADE_FOLDER.exists():\n",
    "    shutil.rmtree(MOCK_CLADE_FOLDER)\n",
    "\n",
    "# Create folder structure\n",
    "MOCK_CLADE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy the test database as db.sqlite\n",
    "shutil.copy(TEST_DB, MOCK_CLADE_FOLDER / 'db.sqlite')\n",
    "\n",
    "print(f\"Created mock clade folder: {MOCK_CLADE_FOLDER}\")\n",
    "print(f\"Contents:\")\n",
    "for f in MOCK_CLADE_FOLDER.iterdir():\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import and Run generate_ontology_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASTSeedMapper class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define RASTSeedMapper class for RAST → seed.role mapping\n",
    "# This is copied from KBDatalakeUtils.py for standalone testing\n",
    "\n",
    "import json\n",
    "\n",
    "class RASTSeedMapper:\n",
    "    \"\"\"Maps RAST annotations to SEED role ontology identifiers.\"\"\"\n",
    "    \n",
    "    def __init__(self, seed_ontology_path: str):\n",
    "        self.seed_mapping = {}\n",
    "        self.multi_func_separators = [' / ', ' @ ', '; ']\n",
    "        self._load_seed_ontology(seed_ontology_path)\n",
    "    \n",
    "    def _load_seed_ontology(self, path: str) -> None:\n",
    "        path = Path(path)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Ontology file not found: {path}\")\n",
    "        \n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        graphs = data.get(\"graphs\", [])\n",
    "        if not graphs:\n",
    "            print(\"Warning: No graphs found in ontology file\")\n",
    "            return\n",
    "            \n",
    "        nodes = graphs[0].get(\"nodes\", [])\n",
    "        \n",
    "        for node in nodes:\n",
    "            label = node.get(\"lbl\")\n",
    "            node_id = node.get(\"id\")\n",
    "            \n",
    "            if not label or not node_id:\n",
    "                continue\n",
    "                \n",
    "            seed_role_id = self._parse_seed_role_id(node_id)\n",
    "            if seed_role_id:\n",
    "                self.seed_mapping[label] = seed_role_id\n",
    "                \n",
    "        print(f\"    Loaded {len(self.seed_mapping)} SEED role mappings\")\n",
    "        \n",
    "    def _parse_seed_role_id(self, raw_id: str) -> str:\n",
    "        if not raw_id:\n",
    "            return None\n",
    "        if \"Role=\" in raw_id:\n",
    "            try:\n",
    "                role_number = raw_id.split(\"Role=\")[-1]\n",
    "                return f\"seed.role:{role_number}\"\n",
    "            except IndexError:\n",
    "                return None\n",
    "        if raw_id.startswith(\"seed.role:\"):\n",
    "            return raw_id\n",
    "        if '_' in raw_id and 'seed.role_' in raw_id:\n",
    "            ontology_part = raw_id.split('/')[-1]\n",
    "            return ontology_part.replace(\"_\", \":\", 1)\n",
    "        return None\n",
    "    \n",
    "    def split_multi_function(self, annotation: str) -> list:\n",
    "        if not annotation:\n",
    "            return []\n",
    "        parts = [annotation]\n",
    "        for separator in self.multi_func_separators:\n",
    "            new_parts = []\n",
    "            for part in parts:\n",
    "                split_parts = part.split(separator)\n",
    "                new_parts.extend(p.strip() for p in split_parts if p.strip())\n",
    "            parts = new_parts\n",
    "        return parts\n",
    "    \n",
    "    def map_annotation(self, annotation: str) -> str:\n",
    "        if not annotation:\n",
    "            return None\n",
    "        if annotation in self.seed_mapping:\n",
    "            return self.seed_mapping[annotation]\n",
    "        parts = self.split_multi_function(annotation)\n",
    "        if len(parts) > 1:\n",
    "            for part in parts:\n",
    "                if part in self.seed_mapping:\n",
    "                    return self.seed_mapping[part]\n",
    "        return None\n",
    "    \n",
    "    def map_all_annotations(self, annotation: str) -> list:\n",
    "        if not annotation:\n",
    "            return []\n",
    "        results = []\n",
    "        if annotation in self.seed_mapping:\n",
    "            results.append((annotation, self.seed_mapping[annotation]))\n",
    "        parts = self.split_multi_function(annotation)\n",
    "        for part in parts:\n",
    "            if part in self.seed_mapping and part != annotation:\n",
    "                results.append((part, self.seed_mapping[part]))\n",
    "        return results\n",
    "\n",
    "print(\"RASTSeedMapper class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ontology_tables function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Full generate_ontology_tables function with RAST mapping, EC column, seed.reaction\n",
    "# Copied from KBDatalakeUtils.py for standalone testing\n",
    "# Updated: Added GO → EC extraction from oio:hasDbXref\n",
    "\n",
    "import sqlite3\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def generate_ontology_tables(\n",
    "    clade_folder: str,\n",
    "    reference_data_path: str = \"/data/reference_data\",\n",
    "    genome_features_table: str = \"genome_features\",\n",
    "    output_folder_name: str = \"ontology_data\"\n",
    ") -> bool:\n",
    "    \"\"\"Generate ontology tables for a clade folder with RAST→seed.role mapping and EC column.\"\"\"\n",
    "    \n",
    "    clade_path = Path(clade_folder)\n",
    "    db_path = clade_path / \"db.sqlite\"\n",
    "    output_path = clade_path / output_folder_name\n",
    "    ref_path = Path(reference_data_path)\n",
    "\n",
    "    if not db_path.exists():\n",
    "        print(f\"Warning: db.sqlite not found in {clade_folder}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Generating ontology tables for: {clade_folder}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        # STEP 1: Load genome features\n",
    "        print(f\"\\n1. Loading genome features from {db_path}...\")\n",
    "        conn = sqlite3.connect(str(db_path))\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{genome_features_table}'\")\n",
    "        if not cursor.fetchone():\n",
    "            print(f\"   Warning: Table '{genome_features_table}' not found\")\n",
    "            conn.close()\n",
    "            return False\n",
    "\n",
    "        genome_df = pd.read_sql_query(f\"SELECT * FROM {genome_features_table}\", conn)\n",
    "        conn.close()\n",
    "        print(f\"   Loaded {len(genome_df)} features\")\n",
    "\n",
    "        # STEP 2: Initialize RASTSeedMapper\n",
    "        print(\"\\n2. Loading RAST → seed.role mapper...\")\n",
    "        seed_json_path = ref_path / \"seed.json\"\n",
    "        mapper = None\n",
    "        if seed_json_path.exists():\n",
    "            mapper = RASTSeedMapper(str(seed_json_path))\n",
    "        else:\n",
    "            print(f\"   Warning: seed.json not found\")\n",
    "\n",
    "        # STEP 3: Extract ontology terms\n",
    "        print(\"\\n3. Extracting ontology terms...\")\n",
    "        terms_by_type = {'GO': set(), 'EC': set(), 'KEGG': set(), 'COG': set(), 'PFAM': set(), 'SO': set(), 'seed.role': set()}\n",
    "        patterns = {\n",
    "            'GO': re.compile(r'GO:\\d+'), 'EC': re.compile(r'EC:[\\d\\.-]+'),\n",
    "            'KEGG': re.compile(r'(?:KEGG:)?K\\d{5}'), 'COG': re.compile(r'COG:(?:COG\\d+|[A-Z])'),\n",
    "            'PFAM': re.compile(r'(?:PFAM:)?PF\\d+(?:\\.\\d+)?'), 'SO': re.compile(r'SO:\\d+'),\n",
    "            'seed.role': re.compile(r'seed\\.role:\\d+'),\n",
    "        }\n",
    "        ec_in_rast_pattern = re.compile(r'\\(EC[:\\s]*([\\d\\.-]+)\\)')\n",
    "        rast_functions = set()\n",
    "        seed_role_to_label = {}\n",
    "        \n",
    "        rast_col = None\n",
    "        for col in ['rast_function', 'rast_functions', 'functions', 'Annotation:SSO']:\n",
    "            if col in genome_df.columns:\n",
    "                rast_col = col\n",
    "                break\n",
    "        if rast_col:\n",
    "            print(f\"   Using RAST function column: {rast_col}\")\n",
    "        \n",
    "        for col in genome_df.columns:\n",
    "            for _, row in genome_df.iterrows():\n",
    "                value = str(row.get(col, ''))\n",
    "                if not value or value == 'nan':\n",
    "                    continue\n",
    "                for ont_type, pattern in patterns.items():\n",
    "                    matches = pattern.findall(value)\n",
    "                    for match in matches:\n",
    "                        if ont_type == 'KEGG' and not match.startswith('KEGG:'):\n",
    "                            match = f'KEGG:{match}'\n",
    "                        elif ont_type == 'PFAM' and not match.startswith('PFAM:'):\n",
    "                            match = f'PFAM:{match}'\n",
    "                        terms_by_type[ont_type].add(match)\n",
    "                if col == rast_col:\n",
    "                    ec_matches = ec_in_rast_pattern.findall(value)\n",
    "                    for ec_num in ec_matches:\n",
    "                        terms_by_type['EC'].add(f'EC:{ec_num}')\n",
    "                    if value and value != 'nan':\n",
    "                        for separator in [' / ', ' @ ', '; ']:\n",
    "                            if separator in value:\n",
    "                                for part in value.split(separator):\n",
    "                                    part = part.strip()\n",
    "                                    if part:\n",
    "                                        rast_functions.add(part)\n",
    "                        if not any(sep in value for sep in [' / ', ' @ ', '; ']):\n",
    "                            rast_functions.add(value)\n",
    "\n",
    "        # STEP 4: Map RAST functions to seed.role IDs\n",
    "        if mapper and rast_functions:\n",
    "            print(f\"\\n4. Mapping {len(rast_functions)} RAST functions to seed.role IDs...\")\n",
    "            for rast_func in rast_functions:\n",
    "                for matched_part, seed_id in mapper.map_all_annotations(rast_func):\n",
    "                    if seed_id:\n",
    "                        terms_by_type['seed.role'].add(seed_id)\n",
    "                        seed_role_to_label[seed_id] = matched_part\n",
    "            print(f\"   Mapped to {len(terms_by_type['seed.role'])} unique seed.role IDs\")\n",
    "        else:\n",
    "            print(\"\\n4. Skipping RAST → seed.role mapping\")\n",
    "\n",
    "        total_terms = sum(len(terms) for terms in terms_by_type.values())\n",
    "        print(f\"\\n   Total unique terms: {total_terms}\")\n",
    "        for ont_type, terms in sorted(terms_by_type.items()):\n",
    "            if terms:\n",
    "                print(f\"     {ont_type}: {len(terms)}\")\n",
    "\n",
    "        if total_terms == 0:\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            pd.DataFrame(columns=['ontology_prefix', 'identifier', 'label', 'definition', 'ec']).to_csv(output_path / 'ontology_terms.tsv', sep='\\t', index=False)\n",
    "            pd.DataFrame(columns=['ontology_prefix', 'definition']).to_csv(output_path / 'ontology_definition.tsv', sep='\\t', index=False)\n",
    "            pd.DataFrame(columns=['subject', 'predicate', 'object']).to_csv(output_path / 'ontology_relationships.tsv', sep='\\t', index=False)\n",
    "            return True\n",
    "\n",
    "        # STEP 5: Enrich terms from parquet files\n",
    "        print(\"\\n5. Enriching terms from local parquet files...\")\n",
    "        enriched_terms = []\n",
    "        statements_df = None\n",
    "        statements_path = ref_path / \"statements.parquet\"\n",
    "        kegg_path = ref_path / \"kegg_ko_definitions.parquet\"\n",
    "        cog_path = ref_path / \"cog_definitions.parquet\"\n",
    "        \n",
    "        berdl_terms = list(terms_by_type['GO'] | terms_by_type['EC'] | terms_by_type['SO'] | terms_by_type['PFAM'] | terms_by_type['seed.role'])\n",
    "        \n",
    "        if berdl_terms and statements_path.exists():\n",
    "            print(f\"   Loading statements.parquet...\")\n",
    "            statements_df = pq.read_table(statements_path).to_pandas()\n",
    "            mask = statements_df['subject'].isin(berdl_terms) & statements_df['predicate'].isin(['rdfs:label', 'IAO:0000115'])\n",
    "            filtered = statements_df[mask]\n",
    "            term_info = {}\n",
    "            for _, row in filtered.iterrows():\n",
    "                subj, pred = row['subject'], row['predicate']\n",
    "                val = row['value'] if 'value' in row else ''\n",
    "                if subj not in term_info:\n",
    "                    term_info[subj] = {'label': '', 'definition': ''}\n",
    "                if pred == 'rdfs:label':\n",
    "                    term_info[subj]['label'] = val\n",
    "                elif pred == 'IAO:0000115':\n",
    "                    term_info[subj]['definition'] = val\n",
    "            for term_id in berdl_terms:\n",
    "                prefix = term_id.split(':')[0]\n",
    "                info = term_info.get(term_id, {'label': '', 'definition': ''})\n",
    "                label = info['label']\n",
    "                if prefix == 'seed.role' and not label and term_id in seed_role_to_label:\n",
    "                    label = seed_role_to_label[term_id]\n",
    "                enriched_terms.append({'ontology_prefix': prefix, 'identifier': term_id, 'label': label, 'definition': info['definition']})\n",
    "            print(f\"   Enriched {len([t for t in enriched_terms if t['label']])} terms with labels\")\n",
    "        \n",
    "        if terms_by_type['KEGG'] and kegg_path.exists():\n",
    "            kegg_df = pq.read_table(kegg_path).to_pandas()\n",
    "            ko_lookup = dict(zip(kegg_df['ko_id'], kegg_df['definition']))\n",
    "            for ko_id in terms_by_type['KEGG']:\n",
    "                k_num = ko_id.replace('KEGG:', '')\n",
    "                definition = ko_lookup.get(k_num, '')\n",
    "                label = re.sub(r'\\s*\\[EC:[^\\]]+\\]', '', definition).strip() if definition else ''\n",
    "                enriched_terms.append({'ontology_prefix': 'KEGG', 'identifier': ko_id, 'label': label, 'definition': definition})\n",
    "        \n",
    "        if terms_by_type['COG'] and cog_path.exists():\n",
    "            cog_df = pq.read_table(cog_path).to_pandas()\n",
    "            cog_lookup = {row['cog_id']: row for _, row in cog_df.iterrows()}\n",
    "            for cog_id in terms_by_type['COG']:\n",
    "                raw_id = cog_id.replace('COG:', '')\n",
    "                info = cog_lookup.get(raw_id, {})\n",
    "                enriched_terms.append({'ontology_prefix': 'COG', 'identifier': cog_id, 'label': info.get('name', '') if isinstance(info, dict) else '', 'definition': info.get('pathway', '') if isinstance(info, dict) else ''})\n",
    "\n",
    "        # STEP 6: Extract relationships\n",
    "        print(\"\\n6. Extracting ontology relationships...\")\n",
    "        relationships = []\n",
    "        all_term_ids = set()\n",
    "        for terms in terms_by_type.values():\n",
    "            all_term_ids.update(terms)\n",
    "        seed_reaction_terms = set()\n",
    "        \n",
    "        if statements_df is not None:\n",
    "            relevant_predicates = {'rdfs:subClassOf', '<https://modelseed.org/ontology/enables_reaction>'}\n",
    "            mask = statements_df['subject'].isin(all_term_ids) & statements_df['predicate'].isin(relevant_predicates)\n",
    "            rel_df = statements_df[mask]\n",
    "            predicate_labels = {'rdfs:subClassOf': 'is_a', '<https://modelseed.org/ontology/enables_reaction>': 'enables_reaction'}\n",
    "            for _, row in rel_df.iterrows():\n",
    "                subj, pred, obj = row['subject'], row['predicate'], row['object']\n",
    "                if subj == obj or str(obj).startswith('_:'):\n",
    "                    continue\n",
    "                if pred == 'rdfs:subClassOf' and (subj.startswith('EC:') or subj.startswith('SO:')):\n",
    "                    continue\n",
    "                if str(obj).startswith('seed.reaction:'):\n",
    "                    seed_reaction_terms.add(obj)\n",
    "                relationships.append({'subject': subj, 'predicate': predicate_labels.get(pred, pred), 'object': obj})\n",
    "            print(f\"   Found {len(relationships)} relationships, {len(seed_reaction_terms)} seed.reaction terms\")\n",
    "            \n",
    "            if seed_reaction_terms:\n",
    "                mask = statements_df['subject'].isin(seed_reaction_terms) & statements_df['predicate'].isin(['rdfs:label', 'IAO:0000115'])\n",
    "                rxn_info = {}\n",
    "                for _, row in statements_df[mask].iterrows():\n",
    "                    subj, pred = row['subject'], row['predicate']\n",
    "                    val = row['value'] if 'value' in row else ''\n",
    "                    if subj not in rxn_info:\n",
    "                        rxn_info[subj] = {'label': '', 'definition': ''}\n",
    "                    if pred == 'rdfs:label':\n",
    "                        rxn_info[subj]['label'] = val\n",
    "                    elif pred == 'IAO:0000115':\n",
    "                        rxn_info[subj]['definition'] = val\n",
    "                for rxn_id in seed_reaction_terms:\n",
    "                    info = rxn_info.get(rxn_id, {'label': '', 'definition': ''})\n",
    "                    enriched_terms.append({'ontology_prefix': 'seed.reaction', 'identifier': rxn_id, 'label': info['label'], 'definition': info['definition']})\n",
    "\n",
    "        # STEP 7: Add EC column (including GO → EC from hasDbXref)\n",
    "        print(\"\\n7. Adding EC column to ontology terms...\")\n",
    "        \n",
    "        # Load KEGG KO → EC mapping\n",
    "        kegg_ec_mapping_path = ref_path / \"kegg_ko_ec_mapping.tsv\"\n",
    "        ko_to_ec = {}\n",
    "        if kegg_ec_mapping_path.exists():\n",
    "            with open(kegg_ec_mapping_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if '\\t' in line:\n",
    "                        ec_raw, ko_raw = line.split('\\t')\n",
    "                        ec_id = ec_raw.replace('ec:', 'EC:')\n",
    "                        ko_id = ko_raw.replace('ko:', 'KEGG:')\n",
    "                        if ko_id not in ko_to_ec:\n",
    "                            ko_to_ec[ko_id] = []\n",
    "                        ko_to_ec[ko_id].append(ec_id)\n",
    "            print(f\"   Loaded {len(ko_to_ec)} KEGG KO -> EC mappings\")\n",
    "        \n",
    "        # Extract GO → EC mapping from statements.parquet (oio:hasDbXref to EC:)\n",
    "        go_to_ec = {}\n",
    "        if statements_df is not None:\n",
    "            print(f\"   Extracting GO -> EC mappings from statements.parquet...\")\n",
    "            go_ec_mask = (\n",
    "                statements_df['subject'].str.startswith('GO:', na=False) &\n",
    "                (statements_df['predicate'] == 'oio:hasDbXref')\n",
    "            )\n",
    "            go_dbxref_df = statements_df[go_ec_mask]\n",
    "            \n",
    "            ec_pattern = re.compile(r'EC:[\\d\\.\\-]+')\n",
    "            for _, row in go_dbxref_df.iterrows():\n",
    "                go_id = row['subject']\n",
    "                # Check both object and value columns for EC reference\n",
    "                obj_val = str(row.get('object', '')) + ' ' + str(row.get('value', ''))\n",
    "                ec_matches = ec_pattern.findall(obj_val)\n",
    "                if ec_matches:\n",
    "                    if go_id not in go_to_ec:\n",
    "                        go_to_ec[go_id] = []\n",
    "                    go_to_ec[go_id].extend(ec_matches)\n",
    "            \n",
    "            # Deduplicate EC values per GO term\n",
    "            for go_id in go_to_ec:\n",
    "                go_to_ec[go_id] = list(set(go_to_ec[go_id]))\n",
    "            \n",
    "            print(f\"   Found {len(go_to_ec)} GO terms with EC cross-references\")\n",
    "        \n",
    "        ec_label_pattern = re.compile(r'\\(EC\\s*([\\d\\.-]+)\\)')\n",
    "        tc_label_pattern = re.compile(r'\\(TC\\s*([\\d\\.\\w]+)\\)')\n",
    "        kegg_ec_count, go_ec_count, seed_ec_count, seed_tc_count, ec_copy_count = 0, 0, 0, 0, 0\n",
    "        \n",
    "        for term in enriched_terms:\n",
    "            ec_values = []\n",
    "            prefix, identifier, label = term['ontology_prefix'], term['identifier'], term.get('label', '')\n",
    "            \n",
    "            if prefix == 'KEGG' and identifier in ko_to_ec:\n",
    "                ec_values.extend(ko_to_ec[identifier])\n",
    "                kegg_ec_count += 1\n",
    "            elif prefix == 'GO' and identifier in go_to_ec:\n",
    "                ec_values.extend(go_to_ec[identifier])\n",
    "                go_ec_count += 1\n",
    "            elif prefix == 'seed.role' and label:\n",
    "                ec_matches = ec_label_pattern.findall(label)\n",
    "                if ec_matches:\n",
    "                    ec_values.extend(['EC:' + m for m in ec_matches])\n",
    "                    seed_ec_count += 1\n",
    "                tc_matches = tc_label_pattern.findall(label)\n",
    "                if tc_matches:\n",
    "                    ec_values.extend(['TC:' + m for m in tc_matches])\n",
    "                    seed_tc_count += 1\n",
    "            elif prefix == 'EC':\n",
    "                ec_values.append(identifier)\n",
    "                ec_copy_count += 1\n",
    "            term['ec'] = '|'.join(ec_values) if ec_values else ''\n",
    "        \n",
    "        print(f\"   KEGG with EC: {kegg_ec_count}, GO with EC: {go_ec_count}, seed.role EC: {seed_ec_count}, TC: {seed_tc_count}, EC copied: {ec_copy_count}\")\n",
    "        print(f\"   Total terms with ec: {sum(1 for t in enriched_terms if t.get('ec'))}\")\n",
    "\n",
    "        # STEP 8: Create ontology definitions\n",
    "        print(\"\\n8. Creating ontology definitions...\")\n",
    "        ontology_definitions = {\n",
    "            'GO': 'Gene Ontology', 'EC': 'Enzyme Commission numbers', 'SO': 'Sequence Ontology',\n",
    "            'PFAM': 'Protein Families database', 'KEGG': 'KEGG Orthologs', 'COG': 'Clusters of Orthologous Groups',\n",
    "            'seed.role': 'SEED Role Ontology', 'seed.reaction': 'SEED Reaction Ontology',\n",
    "        }\n",
    "        present_prefixes = set(t['ontology_prefix'] for t in enriched_terms)\n",
    "        definition_rows = [{'ontology_prefix': p, 'definition': d} for p, d in ontology_definitions.items() if p in present_prefixes]\n",
    "\n",
    "        # STEP 9: Save output\n",
    "        print(f\"\\n9. Saving output to {output_path}...\")\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        terms_df = pd.DataFrame(enriched_terms).drop_duplicates(subset=['identifier'])\n",
    "        terms_df = terms_df.sort_values(['ontology_prefix', 'identifier']).reset_index(drop=True)\n",
    "        terms_df.to_csv(output_path / 'ontology_terms.tsv', sep='\\t', index=False)\n",
    "        print(f\"   Saved {len(terms_df)} terms to ontology_terms.tsv\")\n",
    "        print(f\"   Columns: {list(terms_df.columns)}\")\n",
    "        \n",
    "        pd.DataFrame(definition_rows).to_csv(output_path / 'ontology_definition.tsv', sep='\\t', index=False)\n",
    "        rels_df = pd.DataFrame(relationships)\n",
    "        if not rels_df.empty:\n",
    "            rels_df = rels_df.drop_duplicates()\n",
    "        rels_df.to_csv(output_path / 'ontology_relationships.tsv', sep='\\t', index=False)\n",
    "        print(f\"   Saved {len(rels_df)} relationships\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"Ontology table generation complete!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"\\nError: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "print(\"generate_ontology_tables function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Generating ontology tables for: /home/jplfaria/CDM_jose/ontology_data_utils/test_clade_s__Escherichia_coli\n",
      "======================================================================\n",
      "\n",
      "1. Loading genome features from /home/jplfaria/CDM_jose/ontology_data_utils/test_clade_s__Escherichia_coli/db.sqlite...\n",
      "   Loaded 4617 features\n",
      "\n",
      "2. Loading RAST → seed.role mapper...\n",
      "    Loaded 46232 SEED role mappings\n",
      "\n",
      "3. Extracting ontology terms...\n",
      "   Using RAST function column: rast_function\n",
      "\n",
      "4. Mapping 3952 RAST functions to seed.role IDs...\n",
      "   Mapped to 3951 unique seed.role IDs\n",
      "\n",
      "   Total unique terms: 12009\n",
      "     COG: 1670\n",
      "     EC: 1268\n",
      "     GO: 3544\n",
      "     KEGG: 1485\n",
      "     PFAM: 90\n",
      "     SO: 1\n",
      "     seed.role: 3951\n",
      "\n",
      "5. Enriching terms from local parquet files...\n",
      "   Loading statements.parquet...\n",
      "   Enriched 8612 terms with labels\n",
      "\n",
      "6. Extracting ontology relationships...\n",
      "   Found 7483 relationships, 1443 seed.reaction terms\n",
      "\n",
      "7. Adding EC column to ontology terms...\n",
      "   Loaded 8981 KEGG KO -> EC mappings\n",
      "   Extracting GO -> EC mappings from statements.parquet...\n",
      "   Found 4561 GO terms with EC cross-references\n",
      "   KEGG with EC: 613, GO with EC: 1100, seed.role EC: 1157, TC: 69, EC copied: 1268\n",
      "   Total terms with ec: 4204\n",
      "\n",
      "8. Creating ontology definitions...\n",
      "\n",
      "9. Saving output to /home/jplfaria/CDM_jose/ontology_data_utils/test_clade_s__Escherichia_coli/ontology_data...\n",
      "   Saved 13452 terms to ontology_terms.tsv\n",
      "   Columns: ['ontology_prefix', 'identifier', 'label', 'definition', 'ec']\n",
      "   Saved 7483 relationships\n",
      "\n",
      "======================================================================\n",
      "Ontology table generation complete!\n",
      "======================================================================\n",
      "\n",
      "Result: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Run the function against our mock clade folder\n",
    "result = generate_ontology_tables(\n",
    "    clade_folder=str(MOCK_CLADE_FOLDER),\n",
    "    reference_data_path=str(PARQUET_PATH),\n",
    "    genome_features_table=\"genome_features\",\n",
    "    output_folder_name=\"ontology_data\"\n",
    ")\n",
    "\n",
    "print(f\"\\nResult: {'SUCCESS' if result else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder contents:\n",
      "  ontology_terms.tsv: 1455.7 KB\n",
      "  ontology_definition.tsv: 0.2 KB\n",
      "  ontology_relationships.tsv: 274.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Check output folder\n",
    "output_folder = MOCK_CLADE_FOLDER / 'ontology_data'\n",
    "\n",
    "print(\"Output folder contents:\")\n",
    "if output_folder.exists():\n",
    "    for f in output_folder.iterdir():\n",
    "        size = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name}: {size:.1f} KB\")\n",
    "else:\n",
    "    print(\"  Output folder not created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ontology_terms.tsv: 13452 rows\n",
      "\n",
      "Columns: ['ontology_prefix', 'identifier', 'label', 'definition', 'ec']\n",
      "\n",
      "By ontology_prefix:\n",
      "ontology_prefix\n",
      "seed.role        3951\n",
      "GO               3544\n",
      "COG              1670\n",
      "KEGG             1485\n",
      "seed.reaction    1443\n",
      "EC               1268\n",
      "PFAM               90\n",
      "SO                  1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ontology_prefix</th>\n",
       "      <th>identifier</th>\n",
       "      <th>label</th>\n",
       "      <th>definition</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COG</td>\n",
       "      <td>COG:COG0010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ontology_prefix   identifier label definition   ec\n",
       "0             COG        COG:A   NaN        NaN  NaN\n",
       "1             COG        COG:B   NaN        NaN  NaN\n",
       "2             COG        COG:C   NaN        NaN  NaN\n",
       "3             COG  COG:COG0001   NaN        NaN  NaN\n",
       "4             COG  COG:COG0002   NaN        NaN  NaN\n",
       "5             COG  COG:COG0004   NaN        NaN  NaN\n",
       "6             COG  COG:COG0006   NaN        NaN  NaN\n",
       "7             COG  COG:COG0008   NaN        NaN  NaN\n",
       "8             COG  COG:COG0009   NaN        NaN  NaN\n",
       "9             COG  COG:COG0010   NaN        NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and display ontology_terms.tsv\n",
    "terms_file = output_folder / 'ontology_terms.tsv'\n",
    "if terms_file.exists():\n",
    "    terms_df = pd.read_csv(terms_file, sep='\\t')\n",
    "    print(f\"ontology_terms.tsv: {len(terms_df)} rows\")\n",
    "    print(f\"\\nColumns: {list(terms_df.columns)}\")\n",
    "    print(f\"\\nBy ontology_prefix:\")\n",
    "    print(terms_df['ontology_prefix'].value_counts())\n",
    "    print(f\"\\nSample rows:\")\n",
    "    display(terms_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ontology_definition.tsv: 8 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ontology_prefix</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EC</td>\n",
       "      <td>Enzyme Commission numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SO</td>\n",
       "      <td>Sequence Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PFAM</td>\n",
       "      <td>Protein Families database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KEGG</td>\n",
       "      <td>KEGG Orthologs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COG</td>\n",
       "      <td>Clusters of Orthologous Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seed.role</td>\n",
       "      <td>SEED Role Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seed.reaction</td>\n",
       "      <td>SEED Reaction Ontology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ontology_prefix                      definition\n",
       "0              GO                   Gene Ontology\n",
       "1              EC       Enzyme Commission numbers\n",
       "2              SO               Sequence Ontology\n",
       "3            PFAM       Protein Families database\n",
       "4            KEGG                  KEGG Orthologs\n",
       "5             COG  Clusters of Orthologous Groups\n",
       "6       seed.role              SEED Role Ontology\n",
       "7   seed.reaction          SEED Reaction Ontology"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and display ontology_definition.tsv\n",
    "defs_file = output_folder / 'ontology_definition.tsv'\n",
    "if defs_file.exists():\n",
    "    defs_df = pd.read_csv(defs_file, sep='\\t')\n",
    "    print(f\"ontology_definition.tsv: {len(defs_df)} rows\")\n",
    "    display(defs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ontology_relationships.tsv: 7483 rows\n",
      "\n",
      "Columns: ['subject', 'predicate', 'object']\n",
      "\n",
      "By predicate:\n",
      "predicate\n",
      "is_a                5354\n",
      "enables_reaction    2129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample relationships:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0005385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000014</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0016788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000014</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0004520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000015</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:1902494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000018</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0051052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GO:0000023</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0005984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GO:0000025</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0046352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GO:0000025</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GO:0000027</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0022618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GO:0000028</td>\n",
       "      <td>is_a</td>\n",
       "      <td>GO:0022618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject predicate      object\n",
       "0  GO:0000006      is_a  GO:0005385\n",
       "1  GO:0000014      is_a  GO:0016788\n",
       "2  GO:0000014      is_a  GO:0004520\n",
       "3  GO:0000015      is_a  GO:1902494\n",
       "4  GO:0000018      is_a  GO:0051052\n",
       "5  GO:0000023      is_a  GO:0005984\n",
       "6  GO:0000025      is_a  GO:0046352\n",
       "7  GO:0000025      is_a  GO:0000023\n",
       "8  GO:0000027      is_a  GO:0022618\n",
       "9  GO:0000028      is_a  GO:0022618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and display ontology_relationships.tsv\n",
    "rels_file = output_folder / 'ontology_relationships.tsv'\n",
    "if rels_file.exists():\n",
    "    rels_df = pd.read_csv(rels_file, sep='\\t')\n",
    "    print(f\"ontology_relationships.tsv: {len(rels_df)} rows\")\n",
    "    print(f\"\\nColumns: {list(rels_df.columns)}\")\n",
    "    \n",
    "    if len(rels_df) > 0:\n",
    "        print(f\"\\nBy predicate:\")\n",
    "        print(rels_df['predicate'].value_counts())\n",
    "        \n",
    "        print(f\"\\nSample relationships:\")\n",
    "        display(rels_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION: New Features (including GO → EC)\n",
      "============================================================\n",
      "\n",
      "Columns: ['ontology_prefix', 'identifier', 'label', 'definition', 'ec']\n",
      "\n",
      "EC column: 4204 terms have EC/TC values\n",
      "\n",
      "EC column by ontology prefix:\n",
      "  EC: 1268\n",
      "  GO: 1100\n",
      "  KEGG: 613\n",
      "  seed.role: 1223\n",
      "\n",
      "============================================================\n",
      "GO terms with EC cross-references (from oio:hasDbXref):\n",
      "============================================================\n",
      "Total GO terms with EC: 1100\n",
      "\n",
      "Sample GO → EC mappings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>label</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>GO:0000034</td>\n",
       "      <td>adenine deaminase activity</td>\n",
       "      <td>EC:3.5.4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>GO:0000215</td>\n",
       "      <td>tRNA 2'-phosphotransferase activity</td>\n",
       "      <td>EC:2.7.1.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>GO:0000309</td>\n",
       "      <td>nicotinamide-nucleotide adenylyltransferase ac...</td>\n",
       "      <td>EC:2.7.7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>GO:0000310</td>\n",
       "      <td>xanthine phosphoribosyltransferase activity</td>\n",
       "      <td>EC:2.4.2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>GO:0000701</td>\n",
       "      <td>purine-specific mismatch base pair DNA N-glyco...</td>\n",
       "      <td>EC:3.2.2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>GO:0000810</td>\n",
       "      <td>diacylglycerol diphosphate phosphatase activity</td>\n",
       "      <td>EC:3.6.1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>GO:0000906</td>\n",
       "      <td>6,7-dimethyl-8-ribityllumazine synthase activity</td>\n",
       "      <td>EC:2.5.1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>GO:0000908</td>\n",
       "      <td>taurine dioxygenase activity</td>\n",
       "      <td>EC:1.14.11.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>GO:0002952</td>\n",
       "      <td>(4S)-4-hydroxy-5-phosphonooxypentane-2,3-dione...</td>\n",
       "      <td>EC:5.3.1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>GO:0002953</td>\n",
       "      <td>5'-deoxynucleotidase activity</td>\n",
       "      <td>EC:3.1.3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>GO:0003678</td>\n",
       "      <td>DNA helicase activity</td>\n",
       "      <td>EC:3.6.4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>GO:0003724</td>\n",
       "      <td>RNA helicase activity</td>\n",
       "      <td>EC:3.6.4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>GO:0003755</td>\n",
       "      <td>peptidyl-prolyl cis-trans isomerase activity</td>\n",
       "      <td>EC:5.2.1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>GO:0003756</td>\n",
       "      <td>protein disulfide isomerase activity</td>\n",
       "      <td>EC:5.3.4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>GO:0003796</td>\n",
       "      <td>lysozyme activity</td>\n",
       "      <td>EC:3.2.1.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier                                              label  \\\n",
       "2947  GO:0000034                         adenine deaminase activity   \n",
       "2970  GO:0000215                tRNA 2'-phosphotransferase activity   \n",
       "2979  GO:0000309  nicotinamide-nucleotide adenylyltransferase ac...   \n",
       "2980  GO:0000310        xanthine phosphoribosyltransferase activity   \n",
       "2990  GO:0000701  purine-specific mismatch base pair DNA N-glyco...   \n",
       "2998  GO:0000810    diacylglycerol diphosphate phosphatase activity   \n",
       "3001  GO:0000906   6,7-dimethyl-8-ribityllumazine synthase activity   \n",
       "3002  GO:0000908                       taurine dioxygenase activity   \n",
       "3064  GO:0002952  (4S)-4-hydroxy-5-phosphonooxypentane-2,3-dione...   \n",
       "3065  GO:0002953                      5'-deoxynucleotidase activity   \n",
       "3069  GO:0003678                              DNA helicase activity   \n",
       "3080  GO:0003724                              RNA helicase activity   \n",
       "3089  GO:0003755       peptidyl-prolyl cis-trans isomerase activity   \n",
       "3090  GO:0003756               protein disulfide isomerase activity   \n",
       "3092  GO:0003796                                  lysozyme activity   \n",
       "\n",
       "                 ec  \n",
       "2947     EC:3.5.4.2  \n",
       "2970   EC:2.7.1.160  \n",
       "2979     EC:2.7.7.1  \n",
       "2980    EC:2.4.2.22  \n",
       "2990    EC:3.2.2.31  \n",
       "2998    EC:3.6.1.75  \n",
       "3001    EC:2.5.1.78  \n",
       "3002  EC:1.14.11.17  \n",
       "3064    EC:5.3.1.32  \n",
       "3065    EC:3.1.3.89  \n",
       "3069    EC:3.6.4.12  \n",
       "3080    EC:3.6.4.13  \n",
       "3089     EC:5.2.1.8  \n",
       "3090     EC:5.3.4.1  \n",
       "3092    EC:3.2.1.17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "seed.role terms: 3951\n",
      "seed.reaction terms: 1443\n",
      "enables_reaction relationships: 2129\n"
     ]
    }
   ],
   "source": [
    "# Check specifically for seed.role, seed.reaction, and EC column (new features)\n",
    "terms_file = output_folder / 'ontology_terms.tsv'\n",
    "rels_file = output_folder / 'ontology_relationships.tsv'\n",
    "\n",
    "if terms_file.exists():\n",
    "    terms_df = pd.read_csv(terms_file, sep='\\t')\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"VERIFICATION: New Features (including GO → EC)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check columns include 'ec'\n",
    "    print(f\"\\nColumns: {list(terms_df.columns)}\")\n",
    "    \n",
    "    # Check for EC column content\n",
    "    if 'ec' in terms_df.columns:\n",
    "        ec_filled = terms_df[terms_df['ec'].notna() & (terms_df['ec'] != '')]\n",
    "        print(f\"\\nEC column: {len(ec_filled)} terms have EC/TC values\")\n",
    "        \n",
    "        # By prefix\n",
    "        print(\"\\nEC column by ontology prefix:\")\n",
    "        for prefix in terms_df['ontology_prefix'].unique():\n",
    "            mask = (terms_df['ontology_prefix'] == prefix) & terms_df['ec'].notna() & (terms_df['ec'] != '')\n",
    "            count = mask.sum()\n",
    "            if count > 0:\n",
    "                print(f\"  {prefix}: {count}\")\n",
    "        \n",
    "        # Show GO terms with EC (new feature!)\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"GO terms with EC cross-references (from oio:hasDbXref):\")\n",
    "        print(\"=\" * 60)\n",
    "        go_with_ec = terms_df[(terms_df['ontology_prefix'] == 'GO') & terms_df['ec'].notna() & (terms_df['ec'] != '')]\n",
    "        print(f\"Total GO terms with EC: {len(go_with_ec)}\")\n",
    "        if len(go_with_ec) > 0:\n",
    "            print(\"\\nSample GO → EC mappings:\")\n",
    "            display(go_with_ec[['identifier', 'label', 'ec']].head(15))\n",
    "    \n",
    "    # Check for seed.role\n",
    "    seed_roles = terms_df[terms_df['ontology_prefix'] == 'seed.role']\n",
    "    print(f\"\\nseed.role terms: {len(seed_roles)}\")\n",
    "    \n",
    "    # Check for seed.reaction\n",
    "    seed_reactions = terms_df[terms_df['ontology_prefix'] == 'seed.reaction']\n",
    "    print(f\"seed.reaction terms: {len(seed_reactions)}\")\n",
    "\n",
    "if rels_file.exists():\n",
    "    rels_df = pd.read_csv(rels_file, sep='\\t')\n",
    "    enables_reaction = rels_df[rels_df['predicate'] == 'enables_reaction']\n",
    "    print(f\"enables_reaction relationships: {len(enables_reaction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up test folder\n",
    "# import shutil\n",
    "# if MOCK_CLADE_FOLDER.exists():\n",
    "#     shutil.rmtree(MOCK_CLADE_FOLDER)\n",
    "#     print(f\"Cleaned up: {MOCK_CLADE_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `generate_ontology_tables()` function:\n",
    "\n",
    "1. **Reads** genome features from `db.sqlite` in the clade folder\n",
    "2. **Maps RAST → seed.role** using RASTSeedMapper with seed.json ontology\n",
    "3. **Extracts EC** from RAST function strings (e.g., \"enzyme (EC 1.1.1.1)\")\n",
    "4. **Extracts** ontology terms (GO, EC, KEGG, COG, PFAM, SO, seed.role)\n",
    "5. **Enriches** terms with labels and definitions from local parquet files\n",
    "6. **Extracts** relationships (GO is_a hierarchy, seed.role → enables_reaction → seed.reaction)\n",
    "7. **Adds EC column** to ontology_terms:\n",
    "   - KEGG KO → EC from `kegg_ko_ec_mapping.tsv`\n",
    "   - **GO → EC from `oio:hasDbXref` in statements.parquet** (NEW!)\n",
    "   - seed.role → EC/TC extracted from label\n",
    "   - EC terms → identifier copied\n",
    "8. **Saves** three TSV files to `ontology_data/` subfolder\n",
    "\n",
    "### Output Files:\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `ontology_terms.tsv` | All terms with: ontology_prefix, identifier, label, definition, **ec** |\n",
    "| `ontology_definition.tsv` | Ontology prefix definitions |\n",
    "| `ontology_relationships.tsv` | Term relationships (is_a, enables_reaction) |\n",
    "\n",
    "### EC Column Sources:\n",
    "| Ontology | EC Source |\n",
    "|----------|-----------|\n",
    "| KEGG | `kegg_ko_ec_mapping.tsv` file |\n",
    "| GO | `oio:hasDbXref` → `EC:x.x.x.x` in statements.parquet |\n",
    "| seed.role | Extracted from label: \"(EC 1.1.1.1)\" |\n",
    "| EC | Copied from identifier |\n",
    "\n",
    "### Reference Data Required:\n",
    "- `seed.json` - RAST → seed.role mapping\n",
    "- `statements.parquet` - Labels, definitions, relationships, **GO hasDbXref**\n",
    "- `kegg_ko_definitions.parquet` - KEGG KO definitions\n",
    "- `cog_definitions.parquet` - COG definitions\n",
    "- `kegg_ko_ec_mapping.tsv` - KEGG KO → EC mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelSEED",
   "language": "python",
   "name": "modelseed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
