# KBDatalakeDashboard - Deep Technical Analysis

**Repository:** https://github.com/jplfaria/KBDatalakeDashboard
**Local Path:** `~/repos/KBDatalakeDashboard`
**Purpose:** KBase narrative app that displays interactive dashboards for genome datalake data

---

## Executive Summary

KBDatalakeDashboard is a **viewer/dashboard app** that consumes `KBaseFBA.GenomeDataLakeTables` objects (generated by KBDatalakeApps) and displays them as interactive HTML reports embedded in KBase narratives. The backend is minimal - it simply copies static HTML/JS/CSS to Shock storage. All data fetching and rendering happens client-side via JavaScript connecting to the `berdl_table_scanner` REST API.

**Key Integration Point:** To add the genome heatmap viewer, we can copy the heatmap HTML alongside the existing dashboard and configure it to read the same UPA from `app-config.json`.

---

## 1. Architecture

### KBase SDK Module
- **Type:** Python-based KBase SDK module
- **Module name:** `KBDatalakeDashboard2`
- **Owners:** chenry, jplfaria
- **Version:** 0.0.1

### Deployment
- **Base:** Docker (Python 3.10 slim)
- **Entry:** `scripts/entrypoint.sh` → uwsgi on port 5000
- **Build:** `kb-sdk compile` generates server code from KIDL spec

### Narrative Integration
- **Method:** `run_genome_datalake_dashboard`
- **Input:** `KBaseFBA.GenomeDataLakeTables` object reference (UPA)
- **Output:** KBase HTML report with embedded dashboard
- **Display:** No widget - report renders directly in narrative

---

## 2. Data Flow

### Backend Processing (Minimal)

**Python implementation** (`lib/KBDatalakeDashboard/KBDatalakeDashboardImpl.py:58-132`):

```python
1. Receive input_ref (UPA like "76990/7/2")
2. Create output directory in scratch
3. Copy /kb/module/data/html → output_dir
4. Write app-config.json with {"upa": input_ref}
5. Upload directory to Shock as ZIP
6. Create KBaseReport with shock_id link
7. Return report reference
```

**No data transformation** - backend is just a static file host

### Frontend Processing (All the work)

**JavaScript application** (`data/html/assets/main-*.js`):

```javascript
1. Load app-config.json → get UPA
2. Read KBase session cookie → get auth token
3. Connect to two services:
   - TableScanner: https://appdev.kbase.us/services/berdl_table_scanner
   - Workspace: https://appdev.kbase.us/services/ws
4. Fetch table metadata via Workspace RPC
5. Load table data via TableScanner POST /table-data
6. Render configurable data table
```

**API Endpoints:**
- `GET /object/{upa}/tables` - List available tables
- `GET /object/{upa}/tables/{table}/schema` - Get table schema
- `GET /object/{upa}/tables/{table}/stats` - Get statistics
- `POST /table-data` - Query table with filters/pagination

---

## 3. Code Structure

### Backend (`lib/KBDatalakeDashboard/`)
```
KBDatalakeDashboardImpl.py     Main SDK implementation
  ├─ __init__(config)          Initialize clients
  ├─ _validate_params()        Check required params
  └─ run_genome_datalake_dashboard()  Copy HTML, upload to Shock

installed_clients/             Auto-generated KBase clients
  ├─ DataFileUtilClient.py     Shock file operations
  ├─ KBaseReportClient.py      Report generation
  └─ WorkspaceClient.py        Object retrieval
```

### Frontend (`data/html/`)
```
index.html                     Entry point (loads Vite bundles)
assets/
  ├─ main-*.js                 Bundled application (minified)
  └─ main-*.css                Bundled styles
config/
  ├─ index.json                App settings (API URLs, features)
  ├─ tables/default-config.json  Default table configuration
  └─ schemas/config.schema.json  JSON schema validator
```

### Narrative UI (`ui/narrative/methods/run_genome_datalake_dashboard/`)
```
spec.json                      Parameter definitions
display.yaml                   User-facing descriptions
```

---

## 4. Frontend Technology Stack

### Framework
- **No React/Vue/Svelte** - Custom vanilla JavaScript
- **Build tool:** Vite (modern bundler)
- **Icons:** Bootstrap Icons CDN
- **Fonts:** Inter + JetBrains Mono

### Architecture
- **Component-based** with base `Component` class
- **State management** via `StateManager` (pub/sub pattern)
- **API client** with caching and retry logic
- **Configuration-driven** table rendering

### Key Components
- `ApiClient` - HTTP requests to TableScanner + Workspace
- `ConfigResolver` - Resolve table display configs
- `ConfigManager` - Manage app/table configurations
- `StateManager` - Application state (data, filters, pagination)
- `CategoryManager` - Column categories and visibility
- `Sidebar` - Navigation and control panel

---

## 5. Table Features

### Data Table
- Sortable columns
- Filterable columns (advanced filter panel)
- Pagination (10/25/50/100/250/500 rows per page)
- Row selection
- Cell expansion for long content
- Keyboard navigation
- Column resizing

### Configuration System
**Column schema** (`config/schemas/config.schema.json`):
- Data type (string, number, boolean, date, etc.)
- Visibility (show/hide)
- Sorting enabled/disabled
- Filter type (text, number, date range, select)
- Width, alignment
- **Transforms:** link, badge, number, date, percentage, heatmap, sequence, ontology
- **Conditional styles:** Apply CSS based on cell value

### Export
- CSV (Comma-Separated Values)
- JSON (JavaScript Object Notation)
- TSV (Tab-Separated Values)

---

## 6. Integration Strategy for Genome Heatmap Viewer

### Approach 1: Add as Tab to Existing Dashboard
**Difficulty:** High (requires frontend source code)

**Steps:**
1. Get source code for Vite application (not in repo)
2. Add heatmap tab component to sidebar
3. Configure table schema to include heatmap columns
4. Add heatmap transform type to config schema
5. Rebuild with Vite

**Cons:** Requires access to unmified source

### Approach 2: Separate HTML File in Same Report ✅ RECOMMENDED
**Difficulty:** Low (no source code needed)

**Steps:**
1. Modify `KBDatalakeDashboardImpl.py:79-106`:
   ```python
   # Copy dashboard HTML
   shutil.copytree('/kb/module/data/html', html_dir)

   # Copy heatmap HTML
   shutil.copytree('/kb/module/data/heatmap', f'{html_dir}/heatmap')

   # Write app-config.json (shared by both)
   with open(f'{html_dir}/app-config.json', 'w') as f:
       json.dump({'upa': input_ref}, f)

   # Upload to Shock
   shock_id = dfu.file_to_shock(...)

   # Create report with BOTH HTML files
   html_links = [
       {'shock_id': shock_id, 'name': 'index.html', 'label': 'Data Tables'},
       {'shock_id': shock_id, 'name': 'heatmap/index.html', 'label': 'Gene Heatmap'}
   ]
   ```

2. Create `/kb/module/data/heatmap/index.html`:
   ```html
   <!DOCTYPE html>
   <html>
   <head>
       <title>Genome Heatmap Viewer</title>
       <!-- Copy genome-heatmap-viewer styles -->
   </head>
   <body>
       <div id="kpi-bar"></div>
       <div id="tab-tracks">...</div>
       <script>
           // Load ../app-config.json to get UPA
           // Fetch genes_data from TableScanner or Workspace
           // Render heatmap
       </script>
   </body>
   </html>
   ```

**Benefits:**
- No source code modifications
- Self-contained heatmap page
- Shares auth and UPA config
- Shows as separate tab in KBase report

### Approach 3: Standalone Heatmap App
**Difficulty:** Medium (duplicate SDK module)

**Steps:**
1. Create new repo `KBGenomeHeatmapViewer`
2. Copy SDK boilerplate from KBDatalakeDashboard
3. Accept same `KBaseFBA.GenomeDataLakeTables` input
4. Copy heatmap HTML to `/kb/module/data/html`
5. Deploy as separate narrative app

**Benefits:**
- Independent versioning
- Can be used standalone or with dashboard
- Cleaner separation of concerns

**Cons:**
- More deployment overhead
- User runs two apps instead of one

---

## 7. Recommended Implementation Path

**BEST APPROACH: Approach 2 - Separate HTML in Same Report**

### Phase 1: Create Heatmap HTML Page
1. Copy `index.html` from genome-heatmap-viewer
2. Modify to read `../app-config.json` for UPA
3. Add data loading from TableScanner API:
   ```javascript
   async function loadGenesData(upa) {
       const token = getCookie('kbase_session');
       const response = await fetch(
           'https://appdev.kbase.us/services/berdl_table_scanner/table-data',
           {
               method: 'POST',
               headers: {
                   'Authorization': `Bearer ${token}`,
                   'Content-Type': 'application/json'
               },
               body: JSON.stringify({
                   upa: upa,
                   table: 'genome_features',
                   limit: 10000
               })
           }
       );
       return await response.json();
   }
   ```
4. Transform TableScanner data to genes_data.json format
5. Test standalone

### Phase 2: Integrate into KBDatalakeDashboard
1. Add `/kb/module/data/heatmap/` directory
2. Copy heatmap HTML/CSS/JS
3. Modify `KBDatalakeDashboardImpl.py` to add second html_link
4. Test in KBase narrative
5. Deploy to appdev

### Phase 3: Polish
1. Add loading states
2. Error handling for missing data
3. Responsive design
4. Documentation

---

## 8. Data Mapping: TableScanner → genes_data.json

**TableScanner returns:**
```json
{
  "rows": [
    {
      "genome_id": "user_genome",
      "feature_id": "GENE_001",
      "start": 1000,
      "end": 2000,
      "strand": "+",
      "rast_function": "Pyruvate kinase",
      "ontology_terms": "GO:0004743;KO:K00873",
      ...
    }
  ]
}
```

**Need to transform to:**
```javascript
[
  [
    id,              // row index
    fid,             // feature_id
    length,          // end - start
    start,           // start
    strand,          // strand
    conservation_frac,  // from pangenome table
    pan_category,    // from pangenome table
    function,        // rast_function
    n_ko,            // count KO terms
    n_cog,           // count COG terms
    ...
  ]
]
```

**Mapping function:**
```javascript
function transformToGenesData(rows) {
    return rows.map((row, idx) => [
        idx,                                    // ID
        row.feature_id,                         // FID
        row.end - row.start,                    // LENGTH
        row.start,                              // START
        row.strand === '+' ? 1 : -1,           // STRAND
        row.conservation_frac || null,         // CONS_FRAC
        row.pan_category || 0,                 // PAN_CAT
        row.rast_function || '',               // FUNC
        countOntology(row.ontology_terms, 'KO'), // N_KO
        countOntology(row.ontology_terms, 'COG'), // N_COG
        // ... etc
    ]);
}
```

---

## Next Steps

1. **Fork confirmed** ✅ - `jplfaria/KBDatalakeDashboard` exists
2. **Clone confirmed** ✅ - Repo at `~/repos/KBDatalakeDashboard`
3. **Upstreams added** ✅ - Can sync with kbaseapps/KBDatalakeDashboard

**Ready to start integration!**

